{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd()[-len('irl-chess'):] != 'irl-chess':\n",
    "    os.chdir('../')\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import MeanSquaredError\n",
    "from project import alpha_beta_search, evaluate_board, get_midgame_boards, load_chess_df, san_to_move\n",
    "from tqdm import tqdm\n",
    "import chess\n",
    "from copy import copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:55:25.945182400Z",
     "start_time": "2024-02-20T13:55:22.277364800Z"
    }
   },
   "id": "9ff59d7d65d1ae76",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimpleRegressionModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, initial_weights=None, lr=1e-3):\n",
    "        super(SimpleRegressionModel, self).__init__()\n",
    "        self.lr = lr\n",
    "        # Define the model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, output_size)\n",
    "        )\n",
    "\n",
    "        # Set initial weights if provided\n",
    "        if initial_weights is not None:\n",
    "            self.model[0].weight.data = initial_weights.clone()\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.mse = MeanSquaredError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self(x)\n",
    "        loss = self.loss_function(predictions.squeeze(), y.squeeze())\n",
    "        self.log('train_loss', loss.item(), on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.squeeze()\n",
    "        predictions = self(x).squeeze()\n",
    "        loss = self.loss_function(predictions, y)\n",
    "        self.log('val_loss', loss.item(), on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:20:13.783662700Z",
     "start_time": "2024-02-20T14:20:13.776126300Z"
    }
   },
   "id": "673fe897f8374a55",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_trajectories(boards, R, heuristic=None):\n",
    "    \"\"\"\n",
    "    Return a list of trajectories where each trajectory\n",
    "    has its heuristic value calculated\n",
    "    :param boards: \n",
    "    :param R: \n",
    "    :param heuristic: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if heuristic is None:\n",
    "        heuristic = lambda board: torch.ones_like(R)\n",
    "    trajectories = torch.empty((len(boards), len(R)), dtype=R.dtype, device=R.device)\n",
    "    for i, board in tqdm(enumerate(boards), desc='Generating trajectories', total=len(boards)):\n",
    "        Q, board_, moves = alpha_beta_search(board=board, depth=depth, R=R.cpu().detach().numpy(), maximize=board.turn)\n",
    "        trajectories[i] = heuristic(board_)\n",
    "    return trajectories\n",
    "\n",
    "def eval_boards(boards, moves, R, ):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param boards: \n",
    "    :param R: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    trajectories = torch.empty((len(boards), len(R)), dtype=R.dtype, device=R.device)\n",
    "    for i, (board, move) in tqdm(enumerate(zip(boards, moves)), total=len(boards), desc='Evaluating trajectories'):\n",
    "        board.push(move)\n",
    "        trajectories[i] = evaluate_board(board, R=R, tensor=True)\n",
    "        board.pop()\n",
    "    return trajectories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:06:02.855756900Z",
     "start_time": "2024-02-20T14:06:02.849585700Z"
    }
   },
   "id": "9e9deafb6585c9ce",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_trajectories = 10\n",
    "n_train = 10\n",
    "depth = 3\n",
    "n_epochs = 2\n",
    "min_elo = 1100\n",
    "max_elo = 1300\n",
    "R = torch.rand(6) * 100\n",
    "model = SimpleRegressionModel(input_size=len(R), output_size=1, initial_weights=R.reshape((1, -1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:20:23.301419800Z",
     "start_time": "2024-02-20T14:20:23.296874700Z"
    }
   },
   "id": "3a1be1c6cd007227",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------  1/12  -------------------\n",
      "\n",
      "\n",
      "C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\irl-chess\\data\\processed\\lichess_db_standard_rated_2013-01.csv already exists and was not changed\n",
      "Time taken: 0.00 seconds for file\n",
      "Time taken: 0.00 seconds in total\n",
      "\n",
      "\n",
      "-------------------  2/12  -------------------\n",
      "\n",
      "\n",
      "C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\irl-chess\\data\\processed\\lichess_db_standard_rated_2013-02.csv already exists and was not changed\n",
      "Time taken: 0.00 seconds for file\n",
      "Time taken: 0.00 seconds in total\n",
      "\n",
      "\n",
      "-------------------  3/12  -------------------\n",
      "\n",
      "\n",
      "C:\\Users\\toell\\OneDrive\\Documents\\GitHub\\irl-chess\\data\\processed\\lichess_db_standard_rated_2013-03.csv already exists and was not changed\n",
      "Time taken: 0.00 seconds for file\n",
      "Time taken: 0.00 seconds in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contatenating DataFrames: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "Searching for boards:   0%|          | 1095/402536 [00:00<00:10, 39050.45it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load_chess_df(n_files=3, overwrite=False)\n",
    "boards, moves = get_midgame_boards(df=df, n_boards=n_trajectories, min_elo=min_elo, max_elo=max_elo, sunfish=False, move_translation=san_to_move)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:55:28.816395Z",
     "start_time": "2024-02-20T13:55:25.971881100Z"
    }
   },
   "id": "f0147db818b847d2",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "34eb567917048af8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating trajectories:   0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\n",
      "Generating trajectories:  10%|█         | 1/10 [00:01<00:12,  1.42s/it]\u001B[A\n",
      "Generating trajectories:  20%|██        | 2/10 [00:01<00:06,  1.21it/s]\u001B[A\n",
      "Generating trajectories:  30%|███       | 3/10 [00:02<00:05,  1.23it/s]\u001B[A\n",
      "Generating trajectories:  50%|█████     | 5/10 [00:04<00:04,  1.01it/s]\u001B[A\n",
      "Generating trajectories:  70%|███████   | 7/10 [00:07<00:03,  1.07s/it]\u001B[A\n",
      "Epoch:   0%|          | 0/2 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(n_epochs), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     trajectories_new \u001B[38;5;241m=\u001B[39m \u001B[43mget_trajectories\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboards\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mboards\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     trajectories_eval \u001B[38;5;241m=\u001B[39m eval_boards(boards, moves, R)\n",
      "Cell \u001B[1;32mIn[20], line 14\u001B[0m, in \u001B[0;36mget_trajectories\u001B[1;34m(boards, R, heuristic)\u001B[0m\n\u001B[0;32m     12\u001B[0m trajectories \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty((\u001B[38;5;28mlen\u001B[39m(boards), \u001B[38;5;28mlen\u001B[39m(R)), dtype\u001B[38;5;241m=\u001B[39mR\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mR\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, board \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(boards), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGenerating trajectories\u001B[39m\u001B[38;5;124m'\u001B[39m, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(boards)):\n\u001B[1;32m---> 14\u001B[0m     Q, board_, moves \u001B[38;5;241m=\u001B[39m \u001B[43malpha_beta_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mR\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mboard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mturn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     trajectories[i] \u001B[38;5;241m=\u001B[39m heuristic(board_)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m trajectories\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\irl-chess\\project\\chess_utils\\utils.py:122\u001B[0m, in \u001B[0;36malpha_beta_search\u001B[1;34m(board, depth, alpha, beta, maximize, R, pst, evaluation_function)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m move \u001B[38;5;129;01min\u001B[39;00m board\u001B[38;5;241m.\u001B[39mgenerate_legal_moves():\n\u001B[0;32m    121\u001B[0m     board\u001B[38;5;241m.\u001B[39mpush(move)\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28meval\u001B[39m, board_last, move_queue \u001B[38;5;241m=\u001B[39m \u001B[43malpha_beta_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mpst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluation_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    124\u001B[0m     board\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m min_eval \u001B[38;5;241m>\u001B[39m \u001B[38;5;28meval\u001B[39m:\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\irl-chess\\project\\chess_utils\\utils.py:105\u001B[0m, in \u001B[0;36malpha_beta_search\u001B[1;34m(board, depth, alpha, beta, maximize, R, pst, evaluation_function)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m move \u001B[38;5;129;01min\u001B[39;00m board\u001B[38;5;241m.\u001B[39mgenerate_legal_moves():\n\u001B[0;32m    104\u001B[0m     board\u001B[38;5;241m.\u001B[39mpush(move)\n\u001B[1;32m--> 105\u001B[0m     \u001B[38;5;28meval\u001B[39m, board_last, move_queue \u001B[38;5;241m=\u001B[39m \u001B[43malpha_beta_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mevaluation_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m     board\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_eval \u001B[38;5;241m<\u001B[39m \u001B[38;5;28meval\u001B[39m:\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\irl-chess\\project\\chess_utils\\utils.py:122\u001B[0m, in \u001B[0;36malpha_beta_search\u001B[1;34m(board, depth, alpha, beta, maximize, R, pst, evaluation_function)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m move \u001B[38;5;129;01min\u001B[39;00m board\u001B[38;5;241m.\u001B[39mgenerate_legal_moves():\n\u001B[0;32m    121\u001B[0m     board\u001B[38;5;241m.\u001B[39mpush(move)\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28meval\u001B[39m, board_last, move_queue \u001B[38;5;241m=\u001B[39m \u001B[43malpha_beta_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdepth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mpst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluation_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    124\u001B[0m     board\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m min_eval \u001B[38;5;241m>\u001B[39m \u001B[38;5;28meval\u001B[39m:\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\irl-chess\\project\\chess_utils\\utils.py:97\u001B[0m, in \u001B[0;36malpha_beta_search\u001B[1;34m(board, depth, alpha, beta, maximize, R, pst, evaluation_function)\u001B[0m\n\u001B[0;32m     95\u001B[0m         final_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 97\u001B[0m         final_score \u001B[38;5;241m=\u001B[39m \u001B[43mevaluation_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mboard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m final_score, deepcopy(\n\u001B[0;32m     99\u001B[0m         board), deque()  \u001B[38;5;66;03m# This evaluation function should be static. Positive is good for white and negative is good for black.\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maximize:\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\irl-chess\\project\\chess_utils\\utils.py:64\u001B[0m, in \u001B[0;36mevaluate_board\u001B[1;34m(board, R, pst, white, tensor)\u001B[0m\n\u001B[0;32m     62\u001B[0m             keys[char] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     63\u001B[0m     pos \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([val \u001B[38;5;28;01mfor\u001B[39;00m val \u001B[38;5;129;01min\u001B[39;00m keys\u001B[38;5;241m.\u001B[39mvalues()], dtype\u001B[38;5;241m=\u001B[39mR\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;28;01mif\u001B[39;00m tensor \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([val \u001B[38;5;28;01mfor\u001B[39;00m val \u001B[38;5;129;01min\u001B[39;00m keys\u001B[38;5;241m.\u001B[39mvalues()])\n\u001B[1;32m---> 64\u001B[0m     \u001B[38;5;28meval\u001B[39m \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (pos \u001B[38;5;241m@\u001B[39m R) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m WhitePieces \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Add if\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28meval\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m white \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m+\u001B[39m (eval_pst_only(board) \u001B[38;5;28;01mif\u001B[39;00m pst \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs), desc='Epoch'):\n",
    "    trajectories_new = get_trajectories(boards=boards, R=R, )\n",
    "    trajectories_eval = eval_boards(boards=boards, moves=moves, R=R)\n",
    "    # trajectories = torch.concat((trajectories_eval, trajectories_new))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:03:24.279255900Z",
     "start_time": "2024-02-20T14:03:16.690636Z"
    }
   },
   "id": "45f1f59e66f4b2ec",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[7.7463e+04],\n        [6.6845e+04],\n        [4.4926e+04],\n        [3.9697e-01],\n        [3.9697e-01],\n        [3.9697e-01],\n        [3.9697e-01],\n        [3.9697e-01],\n        [3.9697e-01],\n        [3.9697e-01]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_loss(discriminator, x_human, x_R):\n",
    "    torch.sum(torch.log(discriminator(x_human)))\n",
    "    torch.sum(torch.log(discriminator(x_R)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:22:19.141983Z",
     "start_time": "2024-02-20T14:22:19.135366600Z"
    }
   },
   "id": "b02e8acec18984ea",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.9017],\n         [-0.9017],\n         [-0.9017],\n         [-0.9017],\n         [-0.9017],\n         [-0.9017]], grad_fn=<AddmmBackward0>),)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.ones((6, 6))), "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:11:45.959574700Z",
     "start_time": "2024-02-20T14:11:45.950459200Z"
    }
   },
   "id": "c3007e298220808f",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(254.1658)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R @ torch.ones(6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:09:41.253097600Z",
     "start_time": "2024-02-20T14:09:41.244645200Z"
    }
   },
   "id": "2298dd496f1f3ddb",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ff5730b8238d0f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
