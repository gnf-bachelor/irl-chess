---- Current tasks ----
[x]    Get sunfish up and running.
[x]        Write trainable alpha-beta search function weighted with BIRL heuristics.
[ ]        Combine the two by permuting the weights and using the function to approximate the true ones
[ ]            Evaluate performance
[ ]                Evaluate heuristics qualitatively for different trained chess engines.

[X]    Segment Lichess dataset and make it amenable to Bayesian IRL algorithm.
[ ]        Begin with a small sample.
[ ]    Go through Berkely Deep RL course
[ ]    Read and understand reading list (see reading list section)

[ ]     Consider GAN like architecture with descriminator for policy moves and data moves 
            (optimize reward function to distinguish between policy moves and data moves,
            policy is then informed by that reward function. Sample from that. Gradient step again.)
                Figure out how this works and if we want to try it. 
            




---- Tentative timeline ----

1st March:
    Finish projektplan
    Complete Berkely Deep RL course
    Complete reading list and have strong overview of modern IRL methods

    Ideally having minimum working prototype 

1st April:

1st May:


6th June:
    Submission deadline    

---- Relevant IRL papers reading list ----

    - Bayesian Inverse Reinforcement Learning (The crutch of our project so far)

Important/potentially project changing:
    - Deep Bayesian Reward Learning
    - Scalable Bayesian Inverse Reinforcement Learning
    - Survey of Inverse Reinforcement Learning

Less vital/useful background:
    - Algorithms for Inverse Reinforcement Learning (original Andrew Yang paper)


